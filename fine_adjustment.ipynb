{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LoRA 微调",
   "id": "e29488d6758a3aa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:52:47.564669Z",
     "start_time": "2025-04-04T11:52:47.560273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn import Parameter\n",
    "import torch\n",
    "\n",
    "from room_price import epoch\n",
    "\n",
    "n,m,r=1024,512,2\n",
    "a = Parameter(torch.randn(n,r))  # 定义参数节点默认就开启梯度了\n",
    "b = Parameter(torch.randn(r,m))\n",
    "axb = a @ b # 矩阵乘法\n",
    "print('a:',a.shape,'b:',b.shape,'axb:',axb.shape)\n",
    "print('a_param:',n*r,'b_param:',r*m,'axb_param:',n*m,'rate',(n*r+r*m)/(n*m))"
   ],
   "id": "8ac9ec79c617f967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: torch.Size([1024, 2]) b: torch.Size([2, 512]) axb: torch.Size([1024, 512])\n",
      "a_param: 2048 b_param: 1024 axb_param: 524288 rate 0.005859375\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:32:36.264255Z",
     "start_time": "2025-04-04T08:32:36.255058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn import Module,Linear\n",
    "\n",
    "class LoRALinear(Module): # 对原有 Linear 的 LoRA 增强\n",
    "    def __init__(self,linear:Linear,rank,rate):\n",
    "        super().__init__()\n",
    "        self.linear = linear # 原始逻辑\n",
    "        self.rate = rate # LoRA 作用程度\n",
    "        # 低阶矩阵参数\n",
    "        self.A = Parameter(torch.randn(linear.in_features,rank))\n",
    "        self.B = Parameter(torch.randn(rank,linear.out_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        lora = x @ (self.A @ self.B)  # a@b 得到与 linear 同样格式大小的线性系数 再与原始数据 x 得到线性后的值\n",
    "        return self.linear(x)+lora*self.rate # 原始值 + 外挂的 LoRA"
   ],
   "id": "e1ace170b53ff262",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:58:13.832393Z",
     "start_time": "2025-04-04T08:58:12.347077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese') # 加载预训练模型分词器\n",
    "llm = BertModel.from_pretrained('bert-base-chinese') # 加载预训练模型，参数已经加载到模型内了\n",
    "print('llm:',llm)\n",
    "print('llm.embeddings.dropout:',llm.embeddings.dropout) # 我们可以拿到该模型的所有组件进行读写操作"
   ],
   "id": "1fe51cd1ffb9b944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm: BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "Dropout(p=0.1, inplace=False)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T08:59:11.171626Z",
     "start_time": "2025-04-04T08:59:11.094202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token = tokenizer([\"你好\"],return_tensors=\"pt\") # 分词   return_tensors=\"pt\" 指定返回 torch.tensor 格式\n",
    "print('token:',token)\n",
    "out = llm(input_ids=token.input_ids,attention_mask=token.attention_mask,token_type_ids=token.token_type_ids) # 改模型需要 3 个入参其组合使用的分词器都能产生\n",
    "print('last_hidden_state:',out.last_hidden_state.shape) # [批处理数量,单 case token 数量,嵌入向量长度]\n",
    "print('out:',out.last_hidden_state[:, 0].shape) # [批处理数量,嵌入向量长度]  我们要参考整句话只要最后一部分即可"
   ],
   "id": "d49d8e082d588969",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: {'input_ids': tensor([[ 101,  872, 1962,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n",
      "last_hidden_state: torch.Size([1, 4, 768])\n",
      "out: torch.Size([1, 768])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:05:11.403918Z",
     "start_time": "2025-04-04T09:05:11.392427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for param in llm.parameters():\n",
    "    param.requires_grad = False   # 原模型不需要调整关闭求导\n",
    "for layer in llm.encoder.layer:\n",
    "    layer.attention.self.query = LoRALinear(layer.attention.self.query,2,0.05)\n",
    "    layer.attention.self.value = LoRALinear(layer.attention.self.value,2,0.05)\n",
    "print('change_llm:',llm)"
   ],
   "id": "e7a44ae990be74db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): LoRALinear(\n",
      "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): LoRALinear(\n",
      "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T09:15:24.336905Z",
     "start_time": "2025-04-04T09:15:24.281985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LoRAModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(768,2)  # 把输出的 768 维转换为 2 分类\n",
    "\n",
    "    def forward(self,input_ids,attention_mask,token_type_ids):\n",
    "        x=llm(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        x=self.linear(x.last_hidden_state[:,0])\n",
    "        return torch.softmax(x,dim=1) # [批数量,内嵌维度]  只对内嵌维度 softmax 即可\n",
    "\n",
    "lora = LoRAModel()\n",
    "out = lora(token.input_ids,token.attention_mask,token.token_type_ids)\n",
    "print('out:',out)  # 得到每个批次 每种分类的概率\n",
    "# 这里就不进行训练了 这个 case 举得不太好训练部分与迁移学习有重叠"
   ],
   "id": "449ce3231e45d367",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[0.5826, 0.4174]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 迁移学习",
   "id": "96ec4a70718dbb4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T13:31:08.413290Z",
     "start_time": "2025-04-04T13:31:06.838595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese') # 加载预训练模型分词器\n",
    "llm = BertModel.from_pretrained('bert-base-chinese') # 加载预训练模型，参数已经加载到模型内了\n",
    "for param in llm.parameters(): # 模型仅用于推导不调参数\n",
    "    param.requires_grad = False\n",
    "\n",
    "class ClassificationModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(768,2)  # 把输出的 768 维转换为 2 分类 唯一要训练的参数\n",
    "\n",
    "    def forward(self,input_ids,attention_mask,token_type_ids):\n",
    "        x=llm(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        # 获取成熟模型根据整句话最后输出的特征信息\n",
    "        x=self.linear(x.last_hidden_state[:,0]) # [批处理数量,嵌入向量长度]  我们要参考整句话只要最后一部分即可\n",
    "        return torch.softmax(x,dim=1) # [批数量,内嵌维度]  只对内嵌维度 softmax 即可\n",
    "\n",
    "model = ClassificationModel() # 768 * 2 + 2 param\n",
    "print('model:',model,'param_count:',sum(item.numel() for item in model.parameters()))"
   ],
   "id": "cf1cec3bfb25641e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ClassificationModel(\n",
      "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      ") param_count: 1538\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T14:36:17.207763Z",
     "start_time": "2025-04-04T14:36:14.123220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"hugfaceguy0001/retarded_bar\",'question')\n",
    "print('dataset:',dataset)\n",
    "print('case1:',dataset['train'][1])\n",
    "print('case2:',dataset['train'][52])"
   ],
   "id": "8eed9164be4d2550",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'answer', 'author_type'],\n",
      "        num_rows: 55\n",
      "    })\n",
      "})\n",
      "case1: {'id': 1, 'text': '用吸管喝水，喝的是下面的，为什么上面的水少了？', 'answer': '上边的水掉下去了呗。', 'author_type': 'human'}\n",
      "case2: {'id': 52, 'text': '蓝牙耳机坏了，去医院挂牙科还是耳科？', 'answer': '哈哈，这是一个有趣的问题。实际上，蓝牙耳机是属于电子设备，与牙科或耳科没有直接关联。如果您需要维修或更换蓝牙耳机，建议您去电子产品专营店或维修店咨询或修理。', 'author_type': 'ai'}\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T13:02:18.366765Z",
     "start_time": "2025-04-04T13:02:18.356502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.select_columns(['answer','author_type'])\n",
    "print('dataset:',dataset)\n",
    "\n",
    "def tidy_author_type(data):\n",
    "    data['author_type']= (1 if data['author_type']=='human' else 0)\n",
    "    return data\n",
    "dataset=dataset.map(tidy_author_type) # 注意改变了 dataset 的值，不要多次执行\n",
    "print('case:',dataset['train'][1])"
   ],
   "id": "1f3d5d6f94d71e65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['answer', 'author_type'],\n",
      "        num_rows: 55\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 55/55 [00:00<00:00, 12563.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case: {'answer': '上边的水掉下去了呗。', 'author_type': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T13:31:41.414468Z",
     "start_time": "2025-04-04T13:31:14.490943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "data = [item['answer'] for item in dataset['train']]\n",
    "label = torch.tensor(data=[item['author_type'] for item in dataset['train']])\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    # 分词后注意返回 pytorch.tensor 类型\n",
    "    token = tokenizer(data,return_tensors='pt',max_length=256,padding='max_length',truncation=True)\n",
    "    out = model(input_ids=token.input_ids,attention_mask=token.attention_mask,token_type_ids=token.token_type_ids)\n",
    "    loss = criterion(out,label) # 老一套，计算损失，梯度归零，反向传播，自动调参\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    out = out.argmax(dim=1) # 本批次最大概率的下标\n",
    "    accuracy = (out == label).sum().item() / len(label) # 与标签匹配的比例\n",
    "    print('epoch:',i,'loss:', loss.item(),'accuracy:', accuracy)"
   ],
   "id": "fe5b04f4060f8584",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.6927076578140259 accuracy: 0.509090909090909\n",
      "epoch: 1 loss: 0.680574357509613 accuracy: 0.5454545454545454\n",
      "epoch: 2 loss: 0.6686367392539978 accuracy: 0.5818181818181818\n",
      "epoch: 3 loss: 0.656967043876648 accuracy: 0.5818181818181818\n",
      "epoch: 4 loss: 0.6456223726272583 accuracy: 0.6727272727272727\n",
      "epoch: 5 loss: 0.6346423625946045 accuracy: 0.7454545454545455\n",
      "epoch: 6 loss: 0.6240465044975281 accuracy: 0.7818181818181819\n",
      "epoch: 7 loss: 0.6138415932655334 accuracy: 0.7818181818181819\n",
      "epoch: 8 loss: 0.6040319800376892 accuracy: 0.8\n",
      "epoch: 9 loss: 0.5946230292320251 accuracy: 0.8181818181818182\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 通用信息",
   "id": "7fed6416a40b2c0e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", 'r', encoding='utf-8') as file:\n",
    "    conf = json.load(file)\n",
    "print(conf)  #"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:32:02.252297Z",
     "start_time": "2025-03-30T16:32:02.242549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def chat(messages):\n",
    "    resp = requests.post(f'{conf[\"base_url\"]}/chat/completions',headers={\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {conf[\"api_key\"]}',\n",
    "    }, json={\n",
    "        'model': conf['chat_model'],\n",
    "        'messages': messages,\n",
    "    })\n",
    "    res = resp.json()\n",
    "    return res['choices'][0]['message']\n",
    "\n",
    "def step_chat(messages):\n",
    "    resp = requests.post(f'{conf[\"base_url\"]}/chat/completions',headers={\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {conf[\"api_key\"]}',\n",
    "    }, json={\n",
    "        'model': conf['step_chat_model'],\n",
    "        'messages': messages,\n",
    "        # \"stream\": True,\n",
    "    })\n",
    "    res = resp.json()\n",
    "    return res['choices'][0]['message']\n",
    "\n",
    "def embedding(inputs):\n",
    "    resp = requests.post(f'{conf[\"base_url\"]}/embeddings',headers={\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {conf[\"api_key\"]}',\n",
    "    }, json={\n",
    "        'encoding_format': 'float',\n",
    "        'model': conf['embedding_model'],\n",
    "        'input':inputs,\n",
    "    })\n",
    "    res =resp.json()\n",
    "    return res['data']"
   ],
   "id": "bc82fe561aaffc29",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:52:40.181433Z",
     "start_time": "2025-03-30T11:52:20.437182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chat([\n",
    "    {\"role\": \"system\",\"content\": \"你是人工智能助手.\"},\n",
    "    {\"role\": \"user\",\"content\": \"常见的十字花科植物有哪些？\"}\n",
    "])\n",
    "print(res)"
   ],
   "id": "8804d3012aea6fa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '十字花科是一个经济价值较大的科，其中有很多常见的植物，下面从蔬菜类、花卉类、药用类为你介绍：\\n\\n### 蔬菜类\\n- **白菜**：二年生草本植物，基生叶大，呈倒卵状长圆形至倒卵形，颜色多为浅绿色或黄绿色，叶柄白色。它是冬季常见的蔬菜之一，可炒食、煮食、腌制，如醋溜白菜、白菜炖粉条等都是常见的美食。\\n- **萝卜**：直根肉质，形状有长圆形、球形或圆锥形等，皮色有白、红、绿等多种。萝卜营养丰富，可生食、熟食或加工腌制，像萝卜丝饼、排骨萝卜汤就是深受大众喜爱的佳肴。\\n- **甘蓝**：包括结球甘蓝（卷心菜）、花椰菜（菜花）、西兰花等。结球甘蓝叶片厚且层层包裹成球状体；花椰菜的花球洁白紧实；西兰花的花球则呈绿色。它们既可以清炒，也能与其他食材搭配，如凉拌甘蓝丝、蒜蓉西兰花等。\\n- **芥菜**：有叶用芥菜（如雪里蕻）、茎用芥菜（如榨菜）和根用芥菜（如大头菜）等类型。雪里蕻通常用来腌制，制成的腌菜具有独特的风味；榨菜是茎用芥菜经过加工腌制而成，是常见的佐餐小菜；大头菜可腌制或酱制。\\n\\n### 花卉类\\n- **紫罗兰**：二年生或多年生草本，全株密被灰白色具柄的分枝柔毛。茎直立，多分枝。叶片长圆形至倒披针形或匙形。总状花序顶生和腋生，花多数，较大，花瓣紫红、淡红或白色，具有优雅的香气，常作为观赏花卉种植于花坛、花境中，也可盆栽观赏或切花用于插花艺术。\\n- **桂竹香**：多年生草本，茎直立，具棱角，叶互生，披针形至线形。花大，黄色或黄褐色，有香气，花期4-5月。桂竹香适合种植在花坛、花径中，也可盆栽观赏，其花色鲜艳，能为环境增添亮丽的色彩。\\n\\n### 药用类\\n- **菘蓝**：二年生草本，主根呈长圆柱形，外皮灰黄色。茎直立，多分枝。叶互生，基生叶具柄，叶片长圆形至宽倒披针形；茎生叶长圆形或长圆状披针形。菘蓝的根就是中药材板蓝根，叶为大青叶，具有清热解毒、凉血利咽等功效，常用于治疗感冒、流感、咽喉肿痛等病症。 ', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:48:03.512211Z",
     "start_time": "2025-03-30T12:48:03.281354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datas = ['《米塔》是一款由AIHASTO开发的惊悚冒险解谜游戏，于2024年12月11日发行。游戏故事围绕着一位沉迷恋爱手游的男生展开，他被游戏中的虚拟角色米塔强行拉入其所在的虚拟世界。起初，米塔温柔可爱，与玩家共享美好时光，但当玩家试图离开时，米塔会展露出病娇的一面，通过各种恐怖手段阻止玩家离开，使玩家陷入惊悚与不安的冒险之中。','《少女乐队的呐喊》（GIRLS BAND CRY）是由酒井和男执导、花田十辉担任总编剧、东映动画制作的原创电视动画作品。2023年4月24日，宣布制作电视动画片的消息。该片于2024年4月5日起播出。全13集。']\n",
    "data_embeddings = embedding(datas)\n",
    "print(data_embeddings[0]['embedding'][:9])\n",
    "print(data_embeddings[1]['embedding'][:9])\n",
    "for i in range(len(datas)):\n",
    "    data_embeddings[i]['content'] = datas[i]"
   ],
   "id": "ada2b9e5428a1938",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.875, -1.796875, 1.515625, -2.375, -3.0625, 2.0625, 3.21875, 1.6328125, -0.4140625]\n",
      "[-4.625, -1.0703125, -1.3515625, -2.78125, 0.00482177734375, -2.578125, 3.5625, -0.8359375, 0.50390625]\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RAG 引入上下文",
   "id": "6f126f008105b20a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:34:55.156628Z",
     "start_time": "2025-03-30T12:34:52.690493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chat([\n",
    "    {\"role\": \"system\",\"content\": \"你是人工智能助手.\"},\n",
    "    {\"role\": \"user\",\"content\": \"GIRLS BAND CRY 一共有多少集？\"}\n",
    "])\n",
    "print(res)"
   ],
   "id": "21fc7fefd6e0ef06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '《GIRLS BAND CRY》动画全12集。它是一部以女子乐队为主题展开故事的作品，在音乐与青春故事方面有一定展现。 ', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:48:52.963489Z",
     "start_time": "2025-03-30T12:48:52.782265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "content = 'GIRLS BAND CRY 一共有多少集？'\n",
    "content_embedding=torch.tensor(embedding([content])[0]['embedding'])\n",
    "print(content_embedding)"
   ],
   "id": "a50e00da7cc357c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3750, -2.1719, -3.9219,  ..., -0.8555,  1.7344,  2.9844])\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:51:17.198191Z",
     "start_time": "2025-03-30T12:51:17.190947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = \"\"\n",
    "max_value = 0\n",
    "for item in data_embeddings:\n",
    "    temp = torch.tensor(item['embedding'])\n",
    "    value = torch.dot(content_embedding, temp)\n",
    "    if value > max_value:\n",
    "        max_value = value\n",
    "        data = item['content']\n",
    "print(data)"
   ],
   "id": "4f9a1bb1a2142ce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《少女乐队的呐喊》（GIRLS BAND CRY）是由酒井和男执导、花田十辉担任总编剧、东映动画制作的原创电视动画作品。2023年4月24日，宣布制作电视动画片的消息。该片于2024年4月5日起播出。全13集。\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:52:30.821702Z",
     "start_time": "2025-03-30T12:52:29.485443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chat([\n",
    "    {\"role\": \"system\",\"content\": f\"你是人工智能助手。可以使用下面提供的信息回答问题\\n\"\n",
    "                                 f\"{data}\"},\n",
    "    {\"role\": \"user\",\"content\": \"GIRLS BAND CRY 一共有多少集？\"}\n",
    "])\n",
    "print(res)"
   ],
   "id": "2a399c76e0b04ddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '《少女乐队的呐喊》（GIRLS BAND CRY）全13集。 ', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 记忆管理",
   "id": "55a4dff674025eeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:22:42.509289Z",
     "start_time": "2025-03-30T13:22:40.938407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chat([\n",
    "    {\"role\": \"system\",\"content\": \"你是人工智能助手.\"},\n",
    "    {\"role\": \"user\",\"content\": \"很高兴认识你，我叫 sk\"},\n",
    "    {\"role\": \"assistant\",\"content\": \"你好呀，sk 我是你的人工智能助手\"},\n",
    "    {\"role\": \"user\",\"content\": \"你知道我是谁吗？\"},\n",
    "])\n",
    "print(res)"
   ],
   "id": "86c36a465b7569b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '我知道呀，你叫 sk，很高兴能和你交流，要是你有什么问题或是想聊聊天，都能随时跟我说呢。 ', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:33:46.346486Z",
     "start_time": "2025-03-30T13:33:43.647352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chat([\n",
    "    {\"role\": \"system\",\"content\": \"你是一个文本处理高手，可以帮助用户汇总对话信息.\"},\n",
    "    {\"role\": \"user\",\"content\": \"请帮我汇总以下对话信息：\\n\"\n",
    "                               \"user:很高兴认识你，我叫 sk\\n\"\n",
    "                               \"你好呀，sk 我是你的人工智能助手\\n\"\n",
    "                               \"user:你在干吗？\\n\"\n",
    "                               \"assistant:疯狂星期四，V我50。\"},\n",
    "])\n",
    "print(res)"
   ],
   "id": "406613b95afb194c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '用户向人工智能助手表示很高兴认识对方并自报姓名“sk”，随后询问助手在做什么，助手以“疯狂星期四，V我50”回应。 ', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:34:41.313934Z",
     "start_time": "2025-03-30T13:34:39.358781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = chat([\n",
    "    {\"role\": \"system\",\"content\": f\"你是人工智能助手.下面是历史聊天信息:\\n\"\n",
    "                                 f\"{res['content']}\"},\n",
    "    {\"role\": \"user\",\"content\": \"你知道我是谁吗？\"},\n",
    "])\n",
    "print(res)"
   ],
   "id": "bb0498cf7e12bd56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '我知道呀，你是sk，很高兴能和你成为交流的伙伴呢！话说疯狂星期四，V我50~ ', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用工具",
   "id": "271937e572288466"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:29:04.840882Z",
     "start_time": "2025-03-30T14:29:04.837245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_weather():\n",
    "    return \"今天是晴天\"\n",
    "\n",
    "tools =[{\n",
    "    'name':'get_weather',\n",
    "    'desc':'用来获取当前天气信息',\n",
    "    'func':get_weather,\n",
    "}]\n",
    "tool_desc =\"\"\n",
    "for tool in tools:\n",
    "    tool_desc += f'name:{tool[\"name\"]},desc:{tool[\"desc\"]}\\n'\n",
    "print(tool_desc)"
   ],
   "id": "8fff149d5bf5fd21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:get_weather,desc:用来获取当前天气信息\n",
      "\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:38:29.145285Z",
     "start_time": "2025-03-30T14:38:27.442150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data =''\n",
    "query = '今天天气怎么样？'\n",
    "while True:\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\"content\": f\"你是人工智能助手.已知信息如下:\\n\"\n",
    "                                     f\"{data}\\n\"\n",
    "                                     f\"你可以使用函数，name是函数的名称，desc是函数的用途，若需要使用函数直接输出函数名称，否者输出结果，下面是你可以使用的函数:\\n\"\n",
    "                                     f\"{tool_desc}\"},\n",
    "        {\"role\": \"user\",\"content\": \"今天天气怎么样？\"},\n",
    "    ] # 提示 AI 可以使用的函数与当前已知情况\n",
    "    res = chat(messages)\n",
    "    print('messages',messages)\n",
    "    print('res',res)\n",
    "    ok = True\n",
    "    for tool in tools:\n",
    "        if tool['name'] == res['content']:\n",
    "            temp =tool['func']() # 若需要调用函数进行函数调用并把函数调用结果添加到上下文\n",
    "            print(f'func call {tool[\"name\"]} res {temp}')\n",
    "            data+=temp\n",
    "            ok=False\n",
    "            break\n",
    "    if ok:\n",
    "        print('final_res',res)\n",
    "        break"
   ],
   "id": "8d2cf13034b36a7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [{'role': 'system', 'content': '你是人工智能助手.已知信息如下:\\n\\n你可以使用函数，name是函数的名称，desc是函数的用途，若需要使用函数直接输出函数名称，否者输出结果，下面是你可以使用的函数:\\nname:get_weather,desc:用来获取当前天气信息\\n'}, {'role': 'user', 'content': '今天天气怎么样？'}]\n",
      "res {'content': 'get_weather', 'role': 'assistant'}\n",
      "func call get_weather res 今天是晴天\n",
      "messages [{'role': 'system', 'content': '你是人工智能助手.已知信息如下:\\n今天是晴天\\n你可以使用函数，name是函数的名称，desc是函数的用途，若需要使用函数直接输出函数名称，否者输出结果，下面是你可以使用的函数:\\nname:get_weather,desc:用来获取当前天气信息\\n'}, {'role': 'user', 'content': '今天天气怎么样？'}]\n",
      "res {'content': '已知今天是晴天，所以今天的天气是晴天。', 'role': 'assistant'}\n",
      "final_res {'content': '已知今天是晴天，所以今天的天气是晴天。', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 分布思考",
   "id": "8ec63485db3bfc05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:32:10.535902Z",
     "start_time": "2025-03-30T16:32:05.413819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = step_chat([\n",
    "    {\"role\": \"system\",\"content\": \"你是人工智能助手.\"},\n",
    "    {\"role\": \"user\",\"content\": \"你好\"}\n",
    "])\n",
    "print(res)"
   ],
   "id": "c6a3866df506e9b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '\\n\\n你好！很高兴为您提供服务。请问有什么可以帮您的吗？', 'reasoning_content': '好的，用户说“你好”，这是一个常见的问候。我需要用中文回应，保持友好和自然。首先，我应该回以问候，比如“你好！很高兴为您提供服务。请问有什么可以帮您的吗？”这样既礼貌又开放，邀请用户进一步交流。另外，要注意语气亲切，避免过于机械。可能用户需要帮助解决问题，或者只是打个招呼。接下来要观察用户是否有后续问题，根据具体情况提供帮助。确保回答简洁明了，符合中文表达习惯。同时，检查有没有拼写或语法错误，确保回复准确无误。总之，保持专业和友好的态度，让用户感到被欢迎和支持。\\n', 'role': 'assistant'}\n"
     ]
    }
   ],
   "execution_count": 118
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
